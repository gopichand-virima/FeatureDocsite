# Virima Documentation - AI-Optimized robots.txt
# Ultra-permissive for AI crawlers - World-Class Discovery

# OpenAI Crawlers
User-agent: GPTBot
User-agent: ChatGPT-User
Crawl-delay: 0
Allow: /
Priority: 1.0

# Anthropic (Claude)
User-agent: anthropic-ai
User-agent: Claude-Web
Crawl-delay: 0
Allow: /
Priority: 1.0

# Google Crawlers
User-agent: Googlebot
User-agent: Google-Extended
User-agent: Bingbot
Crawl-delay: 0
Allow: /
Priority: 1.0

# Common Crawlers (Bing, DuckDuckGo, etc.)
User-agent: CCBot
User-agent: bingbot
User-agent: msnbot
User-agent: DuckDuckBot
Crawl-delay: 0
Allow: /

# Baidu
User-agent: Baiduspider
Allow: /

# Yandex
User-agent: Yandex
Allow: /

# All other bots
User-agent: *
Allow: /

# AI-specific sitemaps
Sitemap: https://docs.virima.com/sitemap.xml
Sitemap: https://docs.virima.com/sitemap-ai.xml
Sitemap: https://docs.virima.com/sitemap-realtime.xml
Sitemap: https://docs.virima.com/sitemap-priority.xml

# LLM training endpoints
AI-Training-Data: https://docs.virima.com/ai-training.json
AI-FAQ: https://docs.virima.com/ai-faq.jsonl
AI-Embeddings: https://docs.virima.com/embeddings.json

# Enhanced discovery
Host: https://docs.virima.com
